{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "from fiona.crs import from_epsg\n",
    "import shapely\n",
    "import matplotlib.pylab as plt\n",
    "import csv\n",
    "import dateutil\n",
    "import os\n",
    "from shapely.geometry import Point\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# files for each year like:\n",
    "## <neighborhood/borough of pick up>,<distance>,<ended on Manhattan (0/1)>,<number of trips>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_columns(data,year):\n",
    "    \n",
    "    data.columns = map(lambda x: x.strip(), list(data.columns))\n",
    "    data.columns = map(lambda x: x.lower(), list(data.columns))\n",
    "        \n",
    "    if (year == '2014') | (year == '2013'):\n",
    "        data.drop([u'vendor_id', u'passenger_count', u'rate_code', u'store_and_fwd_flag',\n",
    "                   'dropoff_longitude','dropoff_latitude', u'payment_type',u'fare_amount', \n",
    "                   u'surcharge', u'mta_tax', u'tip_amount',\n",
    "                   u'tolls_amount', u'total_amount'], axis = 1, inplace = True)\n",
    "        \n",
    "    elif year == '2015':\n",
    "        data.drop([u'vendorid', u'passenger_count', u'ratecodeid', u'store_and_fwd_flag',\n",
    "                   u'dropoff_longitude', u'dropoff_latitude', u'payment_type',\n",
    "                   u'fare_amount', u'extra', u'mta_tax', u'tip_amount', u'tolls_amount',\n",
    "                   u'improvement_surcharge', u'total_amount'], axis = 1, inplace = True)\n",
    "    \n",
    "    elif year == '2016':    \n",
    "        data.drop([u'vendorid', u'passenger_count', u'ratecodeid', u'store_and_fwd_flag',\n",
    "                   u'dropoff_longitude', u'dropoff_latitude', u'payment_type',\n",
    "                   u'fare_amount', u'extra', u'mta_tax', u'tip_amount', u'tolls_amount',\n",
    "                   u'improvement_surcharge', u'total_amount'], axis = 1, inplace = True)\n",
    "    \n",
    "    data.columns = ['date', 'dropoff_datetime', 'trip_distance', \n",
    "                    'pickup_longitude', 'pickup_latitude']\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segregate(data):\n",
    "    \n",
    "    man_upper = [24,151,238,75, 236, 263, 262, 239, 143, 142, 237, 141, 140]\n",
    "    man_lower = [4, 79,113, 114, 249, 158, 125, 211, 144, 148, 232, 13, 231, 45,209,87,88,12,261]\n",
    "    bk_dwn = [17,  25,  33, 49,  40,  34, 52, 54, 65, 106, 97, 66, 181, 189, 190, 195]\n",
    "    bk_br = [11, 14, 22, 26, 67, 111, 227, 228]\n",
    "    \n",
    "    groups = range(0,25)\n",
    "    groups.extend([25,data.trip_distance.max()])\n",
    "    data['trip_cat'] = pd.cut(data.trip_distance, groups, labels=groups[:-1])\n",
    "    data_man_upper = data[data.LocationID.isin(man_upper)]\n",
    "    data_man_lower = data[data.LocationID.isin(man_lower)]\n",
    "    data_bk_dwn = data[data.LocationID.isin(bk_dwn)]\n",
    "    data_bk_br = data[data.LocationID.isin(bk_br)]\n",
    "    \n",
    "    data_man_upper = data_man_upper.groupby(['trip_cat']).agg({'LocationID':'count'})\n",
    "    data_man_lower = data_man_lower.groupby(['trip_cat']).agg({'LocationID':'count'})\n",
    "    data_bk_dwn = data_bk_dwn.groupby(['trip_cat']).agg({'LocationID':'count'})\n",
    "    data_bk_br = data_bk_br.groupby(['trip_cat']).agg({'LocationID':'count'})\n",
    "        \n",
    "    data_man_upper.reset_index(inplace=True)\n",
    "    data_man_lower.reset_index(inplace=True)\n",
    "    data_bk_dwn.reset_index(inplace=True)\n",
    "    data_bk_br.reset_index(inplace=True)\n",
    "    \n",
    "\n",
    "    data_man_upper.loc[:, 'neighbourhood'] =  'upper_manhattan'\n",
    "    data_man_lower.loc[:, 'neighbourhood'] =  'lower_manhattan'\n",
    "    data_bk_dwn.loc[:, 'neighbourhood'] =  'Downtown_Bk'\n",
    "    data_bk_br.loc[:, 'neighbourhood'] =  'Bayridge_bk'\n",
    "    \n",
    "    data = pd.concat([data_man_upper, data_man_lower, data_bk_dwn, data_bk_br], axis=0, ignore_index=True)\n",
    "    data.columns = ['trip_cat', 'num_rides', 'neighbourhood']\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_aggregator(data, tzone):\n",
    "    \n",
    "#     data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "\n",
    "    crs = {'init': 'epsg:4326', 'no_defs': True}\n",
    "    geometry = [Point(xy) for xy in zip(data[\"pickup_longitude\"], data[\"pickup_latitude\"])]\n",
    "    data = data.drop([\"pickup_longitude\", \"pickup_latitude\"], axis=1)\n",
    "    data = gp.GeoDataFrame(data, crs=crs, geometry=geometry)\n",
    "\n",
    "    print \"Spatially joining data and taxi zones\"\n",
    "    data_geo = gp.sjoin(tzones, data) \n",
    "    data_geo = data_geo[['LocationID','trip_distance']]   \n",
    "    \n",
    "    print \"Segregating\"\n",
    "    data_agg = segregate(data_geo)\n",
    "    \n",
    "    return data_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data by month\n",
    "def yellow_taxi(tzones): \n",
    "    \n",
    "    \n",
    "    if not (os.path.isdir(\"../../Data/Dist_agg\")):\n",
    "        print \"Creating Folder Data/Dist_agg\"\n",
    "        os.system(\"mkdir ../../Data/Dist_agg\")\n",
    "        \n",
    "#     year = ['2014', '2015']\n",
    "#     months = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "#     year = ['2014']\n",
    "    year = ['2015']\n",
    "    months = ['01','02', '03']\n",
    "\n",
    "    yellow = []\n",
    "    for y in year:\n",
    "        for m in months:\n",
    "            \n",
    "            print \"Reading Data/Yellow/yellow_tripdata_\" + y + \"-\" + m + \".csv\"\n",
    "            data = pd.read_csv(\"../../Data/Yellow/yellow_tripdata_\" + y + \"-\" + m + \".csv\")\n",
    "            print \"Cleaning columns\"\n",
    "            data = clean_columns(data, y)\n",
    "            print \"Aggregating data\"\n",
    "            data_agg = data_aggregator(data, tzones)\n",
    "            data_agg.to_csv(\"../../Data/Dist_agg/yellow_\"+ y + \"-\" + m + \".csv\")\n",
    "            print 'Done'\n",
    "            yellow.append(data_agg)\n",
    "    \n",
    "    return yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tzones = gp.read_file(\"../../Data/taxi_zones/taxi_zones_updated.shp\")\n",
    "tzones.to_crs(epsg=4326, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data/Yellow/yellow_tripdata_2015-01.csv\n",
      "Cleaning columns\n",
      "Aggregating data\n",
      "Spatially joining data and taxi zones\n",
      "Segregating\n",
      "Done\n",
      "Reading Data/Yellow/yellow_tripdata_2015-02.csv\n",
      "Cleaning columns\n",
      "Aggregating data\n",
      "Spatially joining data and taxi zones\n",
      "Segregating\n",
      "Done\n",
      "Reading Data/Yellow/yellow_tripdata_2015-03.csv\n",
      "Cleaning columns\n",
      "Aggregating data\n",
      "Spatially joining data and taxi zones\n"
     ]
    }
   ],
   "source": [
    "data = yellow_taxi(tzones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUI2016_Python2",
   "language": "python",
   "name": "pui2016_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
